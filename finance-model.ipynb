{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2581445,"sourceType":"datasetVersion","datasetId":1567989}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:36:18.030116Z","iopub.execute_input":"2025-07-23T09:36:18.031033Z","iopub.status.idle":"2025-07-23T09:36:18.038013Z","shell.execute_reply.started":"2025-07-23T09:36:18.031008Z","shell.execute_reply":"2025-07-23T09:36:18.037241Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_5min.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_1sec.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/ETH_1min.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_1min.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/ETH_5min.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/ADA_5min.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/ETH_1sec.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/ADA_1sec.csv\n/kaggle/input/high-frequency-crypto-limit-order-book-data/ADA_1min.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_1sec.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:45:10.560058Z","iopub.execute_input":"2025-07-23T09:45:10.560821Z","iopub.status.idle":"2025-07-23T09:45:48.509787Z","shell.execute_reply.started":"2025-07-23T09:45:10.560793Z","shell.execute_reply":"2025-07-23T09:45:48.508924Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:46:00.238131Z","iopub.execute_input":"2025-07-23T09:46:00.238445Z","iopub.status.idle":"2025-07-23T09:46:00.250653Z","shell.execute_reply.started":"2025-07-23T09:46:00.238420Z","shell.execute_reply":"2025-07-23T09:46:00.249805Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'system_time', 'midpoint', 'spread', 'buys', 'sells',\n       'bids_distance_0', 'bids_distance_1', 'bids_distance_2',\n       'bids_distance_3',\n       ...\n       'asks_market_notional_5', 'asks_market_notional_6',\n       'asks_market_notional_7', 'asks_market_notional_8',\n       'asks_market_notional_9', 'asks_market_notional_10',\n       'asks_market_notional_11', 'asks_market_notional_12',\n       'asks_market_notional_13', 'asks_market_notional_14'],\n      dtype='object', length=156)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.rename(columns={\"Unnamed: 0\": \"index\"}, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:50:23.945825Z","iopub.execute_input":"2025-07-23T09:50:23.946084Z","iopub.status.idle":"2025-07-23T09:50:23.950733Z","shell.execute_reply.started":"2025-07-23T09:50:23.946065Z","shell.execute_reply":"2025-07-23T09:50:23.950074Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(list(df.columns))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:51:05.564733Z","iopub.execute_input":"2025-07-23T09:51:05.565382Z","iopub.status.idle":"2025-07-23T09:51:05.569269Z","shell.execute_reply.started":"2025-07-23T09:51:05.565356Z","shell.execute_reply":"2025-07-23T09:51:05.568491Z"}},"outputs":[{"name":"stdout","text":"['index', 'system_time', 'midpoint', 'spread', 'buys', 'sells', 'bids_distance_0', 'bids_distance_1', 'bids_distance_2', 'bids_distance_3', 'bids_distance_4', 'bids_distance_5', 'bids_distance_6', 'bids_distance_7', 'bids_distance_8', 'bids_distance_9', 'bids_distance_10', 'bids_distance_11', 'bids_distance_12', 'bids_distance_13', 'bids_distance_14', 'bids_notional_0', 'bids_notional_1', 'bids_notional_2', 'bids_notional_3', 'bids_notional_4', 'bids_notional_5', 'bids_notional_6', 'bids_notional_7', 'bids_notional_8', 'bids_notional_9', 'bids_notional_10', 'bids_notional_11', 'bids_notional_12', 'bids_notional_13', 'bids_notional_14', 'bids_cancel_notional_0', 'bids_cancel_notional_1', 'bids_cancel_notional_2', 'bids_cancel_notional_3', 'bids_cancel_notional_4', 'bids_cancel_notional_5', 'bids_cancel_notional_6', 'bids_cancel_notional_7', 'bids_cancel_notional_8', 'bids_cancel_notional_9', 'bids_cancel_notional_10', 'bids_cancel_notional_11', 'bids_cancel_notional_12', 'bids_cancel_notional_13', 'bids_cancel_notional_14', 'bids_limit_notional_0', 'bids_limit_notional_1', 'bids_limit_notional_2', 'bids_limit_notional_3', 'bids_limit_notional_4', 'bids_limit_notional_5', 'bids_limit_notional_6', 'bids_limit_notional_7', 'bids_limit_notional_8', 'bids_limit_notional_9', 'bids_limit_notional_10', 'bids_limit_notional_11', 'bids_limit_notional_12', 'bids_limit_notional_13', 'bids_limit_notional_14', 'bids_market_notional_0', 'bids_market_notional_1', 'bids_market_notional_2', 'bids_market_notional_3', 'bids_market_notional_4', 'bids_market_notional_5', 'bids_market_notional_6', 'bids_market_notional_7', 'bids_market_notional_8', 'bids_market_notional_9', 'bids_market_notional_10', 'bids_market_notional_11', 'bids_market_notional_12', 'bids_market_notional_13', 'bids_market_notional_14', 'asks_distance_0', 'asks_distance_1', 'asks_distance_2', 'asks_distance_3', 'asks_distance_4', 'asks_distance_5', 'asks_distance_6', 'asks_distance_7', 'asks_distance_8', 'asks_distance_9', 'asks_distance_10', 'asks_distance_11', 'asks_distance_12', 'asks_distance_13', 'asks_distance_14', 'asks_notional_0', 'asks_notional_1', 'asks_notional_2', 'asks_notional_3', 'asks_notional_4', 'asks_notional_5', 'asks_notional_6', 'asks_notional_7', 'asks_notional_8', 'asks_notional_9', 'asks_notional_10', 'asks_notional_11', 'asks_notional_12', 'asks_notional_13', 'asks_notional_14', 'asks_cancel_notional_0', 'asks_cancel_notional_1', 'asks_cancel_notional_2', 'asks_cancel_notional_3', 'asks_cancel_notional_4', 'asks_cancel_notional_5', 'asks_cancel_notional_6', 'asks_cancel_notional_7', 'asks_cancel_notional_8', 'asks_cancel_notional_9', 'asks_cancel_notional_10', 'asks_cancel_notional_11', 'asks_cancel_notional_12', 'asks_cancel_notional_13', 'asks_cancel_notional_14', 'asks_limit_notional_0', 'asks_limit_notional_1', 'asks_limit_notional_2', 'asks_limit_notional_3', 'asks_limit_notional_4', 'asks_limit_notional_5', 'asks_limit_notional_6', 'asks_limit_notional_7', 'asks_limit_notional_8', 'asks_limit_notional_9', 'asks_limit_notional_10', 'asks_limit_notional_11', 'asks_limit_notional_12', 'asks_limit_notional_13', 'asks_limit_notional_14', 'asks_market_notional_0', 'asks_market_notional_1', 'asks_market_notional_2', 'asks_market_notional_3', 'asks_market_notional_4', 'asks_market_notional_5', 'asks_market_notional_6', 'asks_market_notional_7', 'asks_market_notional_8', 'asks_market_notional_9', 'asks_market_notional_10', 'asks_market_notional_11', 'asks_market_notional_12', 'asks_market_notional_13', 'asks_market_notional_14']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Classification: Will price go up (1) or down (0) in next 10 seconds?\ndf['future_midpoint'] = df['midpoint'].shift(-10)\ndf['price_direction'] = (df['future_midpoint'] > df['midpoint']).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:51:32.394379Z","iopub.execute_input":"2025-07-23T09:51:32.394650Z","iopub.status.idle":"2025-07-23T09:51:32.407459Z","shell.execute_reply.started":"2025-07-23T09:51:32.394628Z","shell.execute_reply":"2025-07-23T09:51:32.406724Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df[\"future_midpoint\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:53:47.306632Z","iopub.execute_input":"2025-07-23T09:53:47.307129Z","iopub.status.idle":"2025-07-23T09:53:47.313408Z","shell.execute_reply.started":"2025-07-23T09:53:47.307106Z","shell.execute_reply":"2025-07-23T09:53:47.312587Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0          56035.995\n1          56035.995\n2          56035.995\n3          56035.995\n4          56035.995\n             ...    \n1030723          NaN\n1030724          NaN\n1030725          NaN\n1030726          NaN\n1030727          NaN\nName: future_midpoint, Length: 1030728, dtype: float64"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Fix the error in the pipeline - the issue is in the create_targets method\n\nclass LOBPipeline:\n    \"\"\"\n    Complete Limit Order Book Machine Learning Pipeline - Fixed Version\n    Supports both classification and regression with swappable algorithms\n    \"\"\"\n    \n    def __init__(self, task_type='classification', scaler_type='standard', \n                 prediction_horizon=10, feature_engineering=True):\n        \"\"\"\n        Initialize the LOB Pipeline\n        \n        Parameters:\n        - task_type: 'classification' or 'regression'\n        - scaler_type: 'standard', 'robust', or None\n        - prediction_horizon: seconds ahead to predict\n        - feature_engineering: whether to create additional features\n        \"\"\"\n        self.task_type = task_type\n        self.scaler_type = scaler_type\n        self.prediction_horizon = prediction_horizon\n        self.feature_engineering = feature_engineering\n        self.scaler = None\n        self.model = None\n        self.feature_columns = None\n        \n    def _create_engineered_features(self, df):\n        \"\"\"Create financial-specific features from LOB data\"\"\"\n        df_eng = df.copy()\n        \n        # Order Imbalance Features\n        bid_volume_total = df_eng[[c for c in df_eng.columns if 'bids_notional_' in c]].sum(axis=1)\n        ask_volume_total = df_eng[[c for c in df_eng.columns if 'asks_notional_' in c]].sum(axis=1)\n        df_eng['order_imbalance'] = (bid_volume_total - ask_volume_total) / (bid_volume_total + ask_volume_total + 1e-8)\n        \n        # Weighted Mid Price (using top 5 levels)\n        bid_prices = []\n        ask_prices = []\n        bid_volumes = []\n        ask_volumes = []\n        \n        for i in range(5):  # Top 5 levels\n            # Calculate actual prices from midpoint and distance\n            bid_price = df_eng['midpoint'] * (1 - df_eng[f'bids_distance_{i}'] / 100)\n            ask_price = df_eng['midpoint'] * (1 + df_eng[f'asks_distance_{i}'] / 100)\n            \n            bid_prices.append(bid_price)\n            ask_prices.append(ask_price)\n            bid_volumes.append(df_eng[f'bids_notional_{i}'])\n            ask_volumes.append(df_eng[f'asks_notional_{i}'])\n        \n        # Volume-weighted average prices\n        total_bid_vol = sum(bid_volumes)\n        total_ask_vol = sum(ask_volumes)\n        \n        vwap_bid = sum([p * v for p, v in zip(bid_prices, bid_volumes)]) / (total_bid_vol + 1e-8)\n        vwap_ask = sum([p * v for p, v in zip(ask_prices, ask_volumes)]) / (total_ask_vol + 1e-8)\n        \n        df_eng['vwap_bid'] = vwap_bid\n        df_eng['vwap_ask'] = vwap_ask\n        df_eng['vwap_midpoint'] = (vwap_bid + vwap_ask) / 2\n        \n        # Price Impact Features\n        df_eng['relative_spread'] = df_eng['spread'] / df_eng['midpoint']\n        \n        # Market/Limit Order Ratios\n        bid_market_total = df_eng[[c for c in df_eng.columns if 'bids_market_notional_' in c]].sum(axis=1)\n        bid_limit_total = df_eng[[c for c in df_eng.columns if 'bids_limit_notional_' in c]].sum(axis=1)\n        ask_market_total = df_eng[[c for c in df_eng.columns if 'asks_market_notional_' in c]].sum(axis=1)\n        ask_limit_total = df_eng[[c for c in df_eng.columns if 'asks_limit_notional_' in c]].sum(axis=1)\n        \n        df_eng['bid_market_ratio'] = bid_market_total / (bid_market_total + bid_limit_total + 1e-8)\n        df_eng['ask_market_ratio'] = ask_market_total / (ask_market_total + ask_limit_total + 1e-8)\n        \n        # Cancel Order Pressure\n        bid_cancel_total = df_eng[[c for c in df_eng.columns if 'bids_cancel_notional_' in c]].sum(axis=1)\n        ask_cancel_total = df_eng[[c for c in df_eng.columns if 'asks_cancel_notional_' in c]].sum(axis=1)\n        \n        df_eng['cancel_pressure'] = (bid_cancel_total - ask_cancel_total) / (bid_cancel_total + ask_cancel_total + 1e-8)\n        \n        # Price momentum features\n        df_eng['midpoint_return_1'] = df_eng['midpoint'].pct_change(1)\n        df_eng['midpoint_return_5'] = df_eng['midpoint'].pct_change(5)\n        df_eng['midpoint_volatility'] = df_eng['midpoint_return_1'].rolling(window=30).std()\n        \n        return df_eng\n    \n    def create_targets(self, df):\n        \"\"\"Create prediction targets based on task type - FIXED VERSION\"\"\"\n        df_targets = df.copy()\n        \n        # Create future midpoint\n        df_targets['future_midpoint'] = df_targets['midpoint'].shift(-self.prediction_horizon)\n        \n        if self.task_type == 'classification':\n            # Binary classification: price goes up (1) or down/stays (0)\n            df_targets['price_direction'] = (df_targets['future_midpoint'] > df_targets['midpoint']).astype(int)\n            df_targets['target'] = df_targets['price_direction']\n        else:\n            # Regression: predict returns\n            df_targets['future_return'] = (df_targets['future_midpoint'] - df_targets['midpoint']) / df_targets['midpoint']\n            df_targets['target'] = df_targets['future_return']\n        \n        # Remove rows with NaN targets (end of dataset)\n        df_targets = df_targets.dropna(subset=['target'])\n        \n        return df_targets\n    \n    def prepare_features(self, df):\n        \"\"\"Prepare feature matrix\"\"\"\n        if self.feature_engineering:\n            df = self._create_engineered_features(df)\n        \n        # Select feature columns (exclude non-feature columns)\n        exclude_cols = ['index', 'system_time', 'future_midpoint', 'price_direction', \n                       'future_return', 'target']\n        \n        feature_cols = [col for col in df.columns if col not in exclude_cols]\n        self.feature_columns = feature_cols\n        \n        X = df[feature_cols].fillna(0)  # Handle any remaining NaN values\n        \n        return X\n    \n    def fit(self, df, model):\n        \"\"\"Fit the pipeline with given model\"\"\"\n        # Create targets\n        df_with_targets = self.create_targets(df)\n        \n        # Prepare features\n        X = self.prepare_features(df_with_targets)\n        y = df_with_targets['target']\n        \n        # Scale features if requested\n        if self.scaler_type == 'standard':\n            self.scaler = StandardScaler()\n            X_scaled = self.scaler.fit_transform(X)\n        elif self.scaler_type == 'robust':\n            self.scaler = RobustScaler()\n            X_scaled = self.scaler.fit_transform(X)\n        else:\n            X_scaled = X.values\n        \n        # Fit model\n        self.model = model\n        self.model.fit(X_scaled, y)\n        \n        return self\n    \n    def predict(self, df):\n        \"\"\"Make predictions on new data\"\"\"\n        # Create targets for consistency (but we won't use them for prediction)\n        df_with_targets = self.create_targets(df)\n        X = self.prepare_features(df_with_targets)\n        \n        if self.scaler is not None:\n            X_scaled = self.scaler.transform(X)\n        else:\n            X_scaled = X.values\n        \n        if self.task_type == 'classification':\n            predictions = self.model.predict(X_scaled)\n            probabilities = self.model.predict_proba(X_scaled)[:, 1] if hasattr(self.model, 'predict_proba') else None\n            return predictions, probabilities\n        else:\n            predictions = self.model.predict(X_scaled)\n            return predictions\n    \n    def evaluate(self, df):\n        \"\"\"Evaluate model performance\"\"\"\n        df_with_targets = self.create_targets(df)\n        X = self.prepare_features(df_with_targets)\n        y_true = df_with_targets['target']\n        \n        if self.scaler is not None:\n            X_scaled = self.scaler.transform(X)\n        else:\n            X_scaled = X.values\n        \n        if self.task_type == 'classification':\n            y_pred = self.model.predict(X_scaled)\n            y_prob = self.model.predict_proba(X_scaled)[:, 1] if hasattr(self.model, 'predict_proba') else None\n            \n            metrics = {\n                'accuracy': accuracy_score(y_true, y_pred),\n                'f1_score': f1_score(y_true, y_pred),\n                'precision': precision_score(y_true, y_pred),\n                'recall': recall_score(y_true, y_pred),\n            }\n            \n            if y_prob is not None:\n                metrics['auc_roc'] = roc_auc_score(y_true, y_prob)\n            \n            # Calculate simple Sharpe ratio simulation\n            # Get the corresponding returns for the prediction period\n            df_returns = df_with_targets.copy()\n            df_returns['actual_return'] = (df_returns['future_midpoint'] - df_returns['midpoint']) / df_returns['midpoint']\n            \n            # Simple strategy: go long when predicting up, short when predicting down  \n            strategy_returns = np.where(y_pred == 1, \n                                      df_returns['actual_return'].fillna(0), \n                                      -df_returns['actual_return'].fillna(0))\n            strategy_returns = strategy_returns[~np.isnan(strategy_returns)]\n            \n            if len(strategy_returns) > 0 and np.std(strategy_returns) > 0:\n                metrics['sharpe_ratio'] = np.mean(strategy_returns) / np.std(strategy_returns) * np.sqrt(252 * 24 * 60)  # Annualized\n            else:\n                metrics['sharpe_ratio'] = 0\n                \n        else:\n            y_pred = self.model.predict(X_scaled)\n            \n            metrics = {\n                'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n                'mae': mean_absolute_error(y_true, y_pred),\n                'r2': r2_score(y_true, y_pred)\n            }\n        \n        return metrics\n\nprint(\"✅ Fixed LOB Pipeline created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:01:41.533203Z","iopub.execute_input":"2025-07-23T10:01:41.533894Z","iopub.status.idle":"2025-07-23T10:01:41.554254Z","shell.execute_reply.started":"2025-07-23T10:01:41.533869Z","shell.execute_reply":"2025-07-23T10:01:41.553494Z"}},"outputs":[{"name":"stdout","text":"✅ Fixed LOB Pipeline created successfully!\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"print(\"Dataset shape:\", df.shape)\nprint(\"\\nColumn names:\")\nprint(df.columns.tolist())\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nData types:\")\nprint(df.dtypes)\nprint(\"\\nBasic statistics:\")\nprint(df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T09:57:57.141961Z","iopub.execute_input":"2025-07-23T09:57:57.142713Z","iopub.status.idle":"2025-07-23T09:58:03.382131Z","shell.execute_reply.started":"2025-07-23T09:57:57.142686Z","shell.execute_reply":"2025-07-23T09:58:03.381157Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (1030728, 158)\n\nColumn names:\n['index', 'system_time', 'midpoint', 'spread', 'buys', 'sells', 'bids_distance_0', 'bids_distance_1', 'bids_distance_2', 'bids_distance_3', 'bids_distance_4', 'bids_distance_5', 'bids_distance_6', 'bids_distance_7', 'bids_distance_8', 'bids_distance_9', 'bids_distance_10', 'bids_distance_11', 'bids_distance_12', 'bids_distance_13', 'bids_distance_14', 'bids_notional_0', 'bids_notional_1', 'bids_notional_2', 'bids_notional_3', 'bids_notional_4', 'bids_notional_5', 'bids_notional_6', 'bids_notional_7', 'bids_notional_8', 'bids_notional_9', 'bids_notional_10', 'bids_notional_11', 'bids_notional_12', 'bids_notional_13', 'bids_notional_14', 'bids_cancel_notional_0', 'bids_cancel_notional_1', 'bids_cancel_notional_2', 'bids_cancel_notional_3', 'bids_cancel_notional_4', 'bids_cancel_notional_5', 'bids_cancel_notional_6', 'bids_cancel_notional_7', 'bids_cancel_notional_8', 'bids_cancel_notional_9', 'bids_cancel_notional_10', 'bids_cancel_notional_11', 'bids_cancel_notional_12', 'bids_cancel_notional_13', 'bids_cancel_notional_14', 'bids_limit_notional_0', 'bids_limit_notional_1', 'bids_limit_notional_2', 'bids_limit_notional_3', 'bids_limit_notional_4', 'bids_limit_notional_5', 'bids_limit_notional_6', 'bids_limit_notional_7', 'bids_limit_notional_8', 'bids_limit_notional_9', 'bids_limit_notional_10', 'bids_limit_notional_11', 'bids_limit_notional_12', 'bids_limit_notional_13', 'bids_limit_notional_14', 'bids_market_notional_0', 'bids_market_notional_1', 'bids_market_notional_2', 'bids_market_notional_3', 'bids_market_notional_4', 'bids_market_notional_5', 'bids_market_notional_6', 'bids_market_notional_7', 'bids_market_notional_8', 'bids_market_notional_9', 'bids_market_notional_10', 'bids_market_notional_11', 'bids_market_notional_12', 'bids_market_notional_13', 'bids_market_notional_14', 'asks_distance_0', 'asks_distance_1', 'asks_distance_2', 'asks_distance_3', 'asks_distance_4', 'asks_distance_5', 'asks_distance_6', 'asks_distance_7', 'asks_distance_8', 'asks_distance_9', 'asks_distance_10', 'asks_distance_11', 'asks_distance_12', 'asks_distance_13', 'asks_distance_14', 'asks_notional_0', 'asks_notional_1', 'asks_notional_2', 'asks_notional_3', 'asks_notional_4', 'asks_notional_5', 'asks_notional_6', 'asks_notional_7', 'asks_notional_8', 'asks_notional_9', 'asks_notional_10', 'asks_notional_11', 'asks_notional_12', 'asks_notional_13', 'asks_notional_14', 'asks_cancel_notional_0', 'asks_cancel_notional_1', 'asks_cancel_notional_2', 'asks_cancel_notional_3', 'asks_cancel_notional_4', 'asks_cancel_notional_5', 'asks_cancel_notional_6', 'asks_cancel_notional_7', 'asks_cancel_notional_8', 'asks_cancel_notional_9', 'asks_cancel_notional_10', 'asks_cancel_notional_11', 'asks_cancel_notional_12', 'asks_cancel_notional_13', 'asks_cancel_notional_14', 'asks_limit_notional_0', 'asks_limit_notional_1', 'asks_limit_notional_2', 'asks_limit_notional_3', 'asks_limit_notional_4', 'asks_limit_notional_5', 'asks_limit_notional_6', 'asks_limit_notional_7', 'asks_limit_notional_8', 'asks_limit_notional_9', 'asks_limit_notional_10', 'asks_limit_notional_11', 'asks_limit_notional_12', 'asks_limit_notional_13', 'asks_limit_notional_14', 'asks_market_notional_0', 'asks_market_notional_1', 'asks_market_notional_2', 'asks_market_notional_3', 'asks_market_notional_4', 'asks_market_notional_5', 'asks_market_notional_6', 'asks_market_notional_7', 'asks_market_notional_8', 'asks_market_notional_9', 'asks_market_notional_10', 'asks_market_notional_11', 'asks_market_notional_12', 'asks_market_notional_13', 'asks_market_notional_14', 'future_midpoint', 'price_direction']\n\nFirst few rows:\n   index                       system_time   midpoint  spread  buys  sells  \\\n0      0  2021-04-07 11:32:42.122161+00:00  56035.995    0.01   0.0    0.0   \n1      1  2021-04-07 11:32:43.122161+00:00  56035.995    0.01   0.0    0.0   \n2      2  2021-04-07 11:32:44.122161+00:00  56035.995    0.01   0.0    0.0   \n3      3  2021-04-07 11:32:45.122161+00:00  56035.995    0.01   0.0    0.0   \n4      4  2021-04-07 11:32:46.122161+00:00  56035.995    0.01   0.0    0.0   \n\n   bids_distance_0  bids_distance_1  bids_distance_2  bids_distance_3  ...  \\\n0    -8.922836e-08    -2.676851e-07         -0.00005        -0.000245  ...   \n1    -8.922836e-08    -2.676851e-07         -0.00005        -0.000245  ...   \n2    -8.922836e-08    -2.676851e-07         -0.00005        -0.000245  ...   \n3    -8.922836e-08    -2.676851e-07         -0.00005        -0.000245  ...   \n4    -8.922836e-08    -2.676851e-07         -0.00005        -0.000245  ...   \n\n   asks_market_notional_7  asks_market_notional_8  asks_market_notional_9  \\\n0                     0.0                     0.0                     0.0   \n1                     0.0                     0.0                     0.0   \n2                     0.0                     0.0                     0.0   \n3                     0.0                     0.0                     0.0   \n4                     0.0                     0.0                     0.0   \n\n   asks_market_notional_10  asks_market_notional_11  asks_market_notional_12  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   asks_market_notional_13  asks_market_notional_14  future_midpoint  \\\n0                      0.0                      0.0        56035.995   \n1                      0.0                      0.0        56035.995   \n2                      0.0                      0.0        56035.995   \n3                      0.0                      0.0        56035.995   \n4                      0.0                      0.0        56035.995   \n\n   price_direction  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 158 columns]\n\nData types:\nindex                        int64\nsystem_time                 object\nmidpoint                   float64\nspread                     float64\nbuys                       float64\n                            ...   \nasks_market_notional_12    float64\nasks_market_notional_13    float64\nasks_market_notional_14    float64\nfuture_midpoint            float64\nprice_direction              int64\nLength: 158, dtype: object\n\nBasic statistics:\n              index      midpoint        spread          buys         sells  \\\ncount  1.030728e+06  1.030728e+06  1.030728e+06  1.030728e+06  1.030728e+06   \nmean   5.153635e+05  5.997507e+04  1.314033e+00  6.060058e+03  5.278900e+03   \nstd    2.975457e+05  2.490049e+03  4.713295e+00  3.234819e+04  3.580757e+04   \nmin    0.000000e+00  5.197818e+04  1.000000e-02  0.000000e+00  0.000000e+00   \n25%    2.576818e+05  5.800001e+04  1.000000e-02  8.971300e+00  0.000000e+00   \n50%    5.153635e+05  6.014658e+04  1.000000e-02  2.640874e+02  0.000000e+00   \n75%    7.730452e+05  6.218776e+04  1.000000e-02  1.747151e+03  6.030148e+02   \nmax    1.030727e+06  6.489675e+04  1.245100e+03  4.060005e+06  5.215817e+06   \n\n       bids_distance_0  bids_distance_1  bids_distance_2  bids_distance_3  \\\ncount     1.030728e+06     1.030728e+06     1.030728e+06     1.030728e+06   \nmean     -1.112330e-05    -4.748918e-05    -7.813118e-05    -1.041134e-04   \nstd       4.152574e-05     6.664107e-05     7.985306e-05     9.147524e-05   \nmin      -1.117184e-02    -1.122119e-02    -1.122191e-02    -1.122873e-02   \n25%      -8.884557e-08    -7.008242e-05    -1.070542e-04    -1.404215e-04   \n50%      -8.387586e-08    -2.803738e-05    -6.124637e-05    -8.584552e-05   \n75%      -8.137923e-08    -2.622042e-06    -2.552932e-05    -4.320817e-05   \nmax      -7.704546e-08    -2.314625e-07    -3.866504e-07    -5.436147e-07   \n\n       bids_distance_4  ...  asks_market_notional_7  asks_market_notional_8  \\\ncount     1.030728e+06  ...            1.030728e+06            1.030728e+06   \nmean     -1.284544e-04  ...            1.547479e+01            1.187494e+01   \nstd       1.014943e-04  ...            7.454360e+02            7.368599e+02   \nmin      -1.122891e-02  ...            0.000000e+00            0.000000e+00   \n25%      -1.708368e-04  ...            0.000000e+00            0.000000e+00   \n50%      -1.094235e-04  ...            0.000000e+00            0.000000e+00   \n75%      -6.204078e-05  ...            0.000000e+00            0.000000e+00   \nmax      -7.036742e-07  ...            2.398862e+05            2.842566e+05   \n\n       asks_market_notional_9  asks_market_notional_10  \\\ncount            1.030728e+06             1.030728e+06   \nmean             1.126070e+01             7.655287e+00   \nstd              1.605108e+03             5.374839e+02   \nmin              0.000000e+00             0.000000e+00   \n25%              0.000000e+00             0.000000e+00   \n50%              0.000000e+00             0.000000e+00   \n75%              0.000000e+00             0.000000e+00   \nmax              1.515275e+06             2.573839e+05   \n\n       asks_market_notional_11  asks_market_notional_12  \\\ncount             1.030728e+06             1.030728e+06   \nmean              7.016595e+00             4.484935e+00   \nstd               6.842541e+02             4.504661e+02   \nmin               0.000000e+00             0.000000e+00   \n25%               0.000000e+00             0.000000e+00   \n50%               0.000000e+00             0.000000e+00   \n75%               0.000000e+00             0.000000e+00   \nmax               3.478454e+05             1.848533e+05   \n\n       asks_market_notional_13  asks_market_notional_14  future_midpoint  \\\ncount             1.030728e+06             1.030728e+06     1.030718e+06   \nmean              2.733226e+00             2.007459e+00     5.997511e+04   \nstd               3.084014e+02             2.513386e+02     2.490031e+03   \nmin               0.000000e+00             0.000000e+00     5.197818e+04   \n25%               0.000000e+00             0.000000e+00     5.800001e+04   \n50%               0.000000e+00             0.000000e+00     6.014658e+04   \n75%               0.000000e+00             0.000000e+00     6.218777e+04   \nmax               1.108049e+05             1.174619e+05     6.489675e+04   \n\n       price_direction  \ncount     1.030728e+06  \nmean      4.204058e-01  \nstd       4.936243e-01  \nmin       0.000000e+00  \n25%       0.000000e+00  \n50%       0.000000e+00  \n75%       1.000000e+00  \nmax       1.000000e+00  \n\n[8 rows x 157 columns]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"df_clean = df.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:01:53.608033Z","iopub.execute_input":"2025-07-23T10:01:53.608580Z","iopub.status.idle":"2025-07-23T10:01:54.520283Z","shell.execute_reply.started":"2025-07-23T10:01:53.608556Z","shell.execute_reply":"2025-07-23T10:01:54.519561Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm.auto import tqdm\nimport numpy as np\n\n# Enable tqdm for pandas - this MUST come before using progress_apply\ntqdm.pandas()\ndef calc_order_imbalance(row):\n    bid_vol = sum(row[f'bids_notional_{i}'] for i in range(15))\n    ask_vol = sum(row[f'asks_notional_{i}'] for i in range(15))\n    return (bid_vol - ask_vol) / (bid_vol + ask_vol)\n\ndf['order_imbalance'] = df.progress_apply(calc_order_imbalance, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:13:50.512458Z","iopub.execute_input":"2025-07-23T10:13:50.513083Z","iopub.status.idle":"2025-07-23T10:15:01.446527Z","shell.execute_reply.started":"2025-07-23T10:13:50.513060Z","shell.execute_reply":"2025-07-23T10:15:01.445896Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1030728 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52bed34d800042d1802c69cf11c200e0"}},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"# 3. Temporal split (same as before)\nsplit = int(len(df) * 0.8)\ntrain, test = df.iloc[:split], df.iloc[split:]\n\n# 4. Initialise pipeline\npipeline = LOBPipeline(\n    task_type='classification',\n    scaler_type='standard',\n    prediction_horizon=10,\n    feature_engineering=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:20:01.333755Z","iopub.execute_input":"2025-07-23T10:20:01.334290Z","iopub.status.idle":"2025-07-23T10:20:01.338800Z","shell.execute_reply.started":"2025-07-23T10:20:01.334266Z","shell.execute_reply":"2025-07-23T10:20:01.338236Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"\n\n# 5. Model with verbose iterations so tqdm can hook in\nmodel = GradientBoostingClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    verbose=0              # keep sklearn quiet; tqdm will handle output\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:20:12.048173Z","iopub.execute_input":"2025-07-23T10:20:12.048453Z","iopub.status.idle":"2025-07-23T10:20:12.052226Z","shell.execute_reply.started":"2025-07-23T10:20:12.048434Z","shell.execute_reply":"2025-07-23T10:20:12.051370Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# 6. Fit with progress bar on iterations\nprint(\"Training model ...\")\nwith tqdm(total=model.n_estimators, desc=\"GB Boost rounds\") as pbar:\n    # monkey-patch the model’s internal _fit_stage to update pbar\n    orig_fit_stage = model._fit_stage\n    def _fit_stage_with_pbar(*args, **kwargs):\n        pbar.update(1)\n        return orig_fit_stage(*args, **kwargs)\n    model._fit_stage = _fit_stage_with_pbar\n\n    pipeline.fit(train, model)\n    pbar.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:20:19.463863Z","iopub.execute_input":"2025-07-23T10:20:19.464429Z","iopub.status.idle":"2025-07-23T10:28:21.492166Z","shell.execute_reply.started":"2025-07-23T10:20:19.464406Z","shell.execute_reply":"2025-07-23T10:28:21.491229Z"}},"outputs":[{"name":"stdout","text":"Training model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"GB Boost rounds:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e83fb1a9294e83a3d7dd6bed834245"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1931174324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fit_stage_with_pbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2988423244.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, model)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1931174324.py\u001b[0m in \u001b[0;36m_fit_stage_with_pbar\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_stage_with_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0morig_fit_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fit_stage_with_pbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"# 7. Evaluation with progress on batches\nprint(\"Evaluating ...\")\nbatch_size = 50_000\ny_true, y_pred = [], []\nfor start in tqdm(range(0, len(test), batch_size), desc=\"Scoring batches\"):\n    end = start + batch_size\n    batch = test.iloc[start:end]\n    preds = pipeline.predict(batch)\n    y_pred.extend(preds)\n    y_true.extend(batch['price_direction'].values)\n\nmetrics = pipeline.metric_dict(y_true, y_pred)\nprint(\"Test metrics →\", metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Gpu Usage","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom tqdm.auto import tqdm; tqdm.pandas()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PRED_HORIZON = 10\nCSV_PATH = '/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_1sec.csv'\n\ndf = pd.read_csv(CSV_PATH, low_memory=False)\ndf['future_midpoint'] = df['midpoint'].shift(-PRED_HORIZON)\ndf['price_direction'] = (df['future_midpoint'] > df['midpoint']).astype(int)\ndf = df.dropna(subset=['price_direction'])\n\nfeature_cols = [\n    c for c in df.columns\n    if c not in ['price_direction', 'future_midpoint', 'midpoint', 'system_time', 'index']\n       and df[c].dtype != 'object'\n]\n\nX = df[feature_cols]\ny = df['price_direction']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:28:42.373300Z","iopub.execute_input":"2025-07-23T10:28:42.373874Z","iopub.status.idle":"2025-07-23T10:29:26.258826Z","shell.execute_reply.started":"2025-07-23T10:28:42.373848Z","shell.execute_reply":"2025-07-23T10:29:26.258227Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndtest  = xgb.DMatrix(X_test,  label=y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:29:51.273643Z","iopub.execute_input":"2025-07-23T10:29:51.273920Z","iopub.status.idle":"2025-07-23T10:29:54.602770Z","shell.execute_reply.started":"2025-07-23T10:29:51.273899Z","shell.execute_reply":"2025-07-23T10:29:54.602228Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"params = {\n    'objective'      : 'binary:logistic',\n    'eval_metric'    : ['auc', 'logloss'],\n    'tree_method'    : 'gpu_hist',      # key line: use GPU for histogram building\n    'predictor'      : 'gpu_predictor', # GPU inference\n    'gpu_id'         : 0,               # default GPU\n    'learning_rate'  : 0.05,\n    'max_depth'      : 6,\n    'subsample'      : 0.8,\n    'colsample_bytree': 0.8,\n    'verbosity'      : 1\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:29:58.474815Z","iopub.execute_input":"2025-07-23T10:29:58.475436Z","iopub.status.idle":"2025-07-23T10:29:58.479353Z","shell.execute_reply.started":"2025-07-23T10:29:58.475414Z","shell.execute_reply":"2025-07-23T10:29:58.478558Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"num_rounds = 1000\nmodel = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_rounds,\n    evals=[(dtrain, 'train'), (dtest, 'valid')],\n    verbose_eval=25     # progress every 25 rounds\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:30:42.448745Z","iopub.execute_input":"2025-07-23T10:30:42.449360Z","iopub.status.idle":"2025-07-23T10:31:10.828422Z","shell.execute_reply.started":"2025-07-23T10:30:42.449337Z","shell.execute_reply":"2025-07-23T10:31:10.827858Z"}},"outputs":[{"name":"stdout","text":"[0]\ttrain-auc:0.69268\ttrain-logloss:0.67247\tvalid-auc:0.63623\tvalid-logloss:0.68724\n[25]\ttrain-auc:0.70592\ttrain-logloss:0.61944\tvalid-auc:0.65420\tvalid-logloss:0.65287\n[50]\ttrain-auc:0.71102\ttrain-logloss:0.60900\tvalid-auc:0.65721\tvalid-logloss:0.64724\n[75]\ttrain-auc:0.71525\ttrain-logloss:0.60465\tvalid-auc:0.65911\tvalid-logloss:0.64547\n[100]\ttrain-auc:0.71835\ttrain-logloss:0.60189\tvalid-auc:0.65979\tvalid-logloss:0.64502\n[125]\ttrain-auc:0.72109\ttrain-logloss:0.59964\tvalid-auc:0.66067\tvalid-logloss:0.64449\n[150]\ttrain-auc:0.72351\ttrain-logloss:0.59775\tvalid-auc:0.66098\tvalid-logloss:0.64435\n[175]\ttrain-auc:0.72599\ttrain-logloss:0.59597\tvalid-auc:0.66108\tvalid-logloss:0.64428\n[200]\ttrain-auc:0.72820\ttrain-logloss:0.59436\tvalid-auc:0.66091\tvalid-logloss:0.64435\n[225]\ttrain-auc:0.73037\ttrain-logloss:0.59278\tvalid-auc:0.66072\tvalid-logloss:0.64451\n[250]\ttrain-auc:0.73269\ttrain-logloss:0.59117\tvalid-auc:0.66034\tvalid-logloss:0.64480\n[275]\ttrain-auc:0.73470\ttrain-logloss:0.58975\tvalid-auc:0.66046\tvalid-logloss:0.64484\n[300]\ttrain-auc:0.73662\ttrain-logloss:0.58842\tvalid-auc:0.66046\tvalid-logloss:0.64489\n[325]\ttrain-auc:0.73866\ttrain-logloss:0.58695\tvalid-auc:0.66051\tvalid-logloss:0.64491\n[350]\ttrain-auc:0.74056\ttrain-logloss:0.58563\tvalid-auc:0.66029\tvalid-logloss:0.64508\n[375]\ttrain-auc:0.74238\ttrain-logloss:0.58437\tvalid-auc:0.66030\tvalid-logloss:0.64521\n[400]\ttrain-auc:0.74420\ttrain-logloss:0.58308\tvalid-auc:0.66021\tvalid-logloss:0.64532\n[425]\ttrain-auc:0.74591\ttrain-logloss:0.58186\tvalid-auc:0.66011\tvalid-logloss:0.64540\n[450]\ttrain-auc:0.74780\ttrain-logloss:0.58052\tvalid-auc:0.66013\tvalid-logloss:0.64550\n[475]\ttrain-auc:0.74952\ttrain-logloss:0.57929\tvalid-auc:0.65998\tvalid-logloss:0.64564\n[500]\ttrain-auc:0.75134\ttrain-logloss:0.57801\tvalid-auc:0.66011\tvalid-logloss:0.64562\n[525]\ttrain-auc:0.75305\ttrain-logloss:0.57679\tvalid-auc:0.66014\tvalid-logloss:0.64559\n[550]\ttrain-auc:0.75463\ttrain-logloss:0.57565\tvalid-auc:0.66008\tvalid-logloss:0.64564\n[575]\ttrain-auc:0.75651\ttrain-logloss:0.57433\tvalid-auc:0.65987\tvalid-logloss:0.64574\n[600]\ttrain-auc:0.75808\ttrain-logloss:0.57320\tvalid-auc:0.65968\tvalid-logloss:0.64587\n[625]\ttrain-auc:0.75966\ttrain-logloss:0.57207\tvalid-auc:0.65967\tvalid-logloss:0.64589\n[650]\ttrain-auc:0.76119\ttrain-logloss:0.57101\tvalid-auc:0.65969\tvalid-logloss:0.64591\n[675]\ttrain-auc:0.76273\ttrain-logloss:0.56989\tvalid-auc:0.65973\tvalid-logloss:0.64597\n[700]\ttrain-auc:0.76433\ttrain-logloss:0.56876\tvalid-auc:0.65959\tvalid-logloss:0.64609\n[725]\ttrain-auc:0.76586\ttrain-logloss:0.56765\tvalid-auc:0.65953\tvalid-logloss:0.64618\n[750]\ttrain-auc:0.76734\ttrain-logloss:0.56652\tvalid-auc:0.65951\tvalid-logloss:0.64623\n[775]\ttrain-auc:0.76898\ttrain-logloss:0.56535\tvalid-auc:0.65899\tvalid-logloss:0.64673\n[800]\ttrain-auc:0.77038\ttrain-logloss:0.56435\tvalid-auc:0.65898\tvalid-logloss:0.64676\n[825]\ttrain-auc:0.77183\ttrain-logloss:0.56328\tvalid-auc:0.65889\tvalid-logloss:0.64688\n[850]\ttrain-auc:0.77332\ttrain-logloss:0.56219\tvalid-auc:0.65897\tvalid-logloss:0.64683\n[875]\ttrain-auc:0.77461\ttrain-logloss:0.56123\tvalid-auc:0.65900\tvalid-logloss:0.64686\n[900]\ttrain-auc:0.77611\ttrain-logloss:0.56016\tvalid-auc:0.65891\tvalid-logloss:0.64690\n[925]\ttrain-auc:0.77762\ttrain-logloss:0.55903\tvalid-auc:0.65879\tvalid-logloss:0.64702\n[950]\ttrain-auc:0.77898\ttrain-logloss:0.55799\tvalid-auc:0.65874\tvalid-logloss:0.64705\n[975]\ttrain-auc:0.78035\ttrain-logloss:0.55698\tvalid-auc:0.65873\tvalid-logloss:0.64716\n[999]\ttrain-auc:0.78176\ttrain-logloss:0.55593\tvalid-auc:0.65862\tvalid-logloss:0.64730\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"pred_prob = model.predict(dtest)\npred_bin  = (pred_prob > 0.5).astype(int)\n\nprint(\"Accuracy :\", accuracy_score(y_test, pred_bin))\nprint(\"F1-score :\", f1_score(y_test, pred_bin))\nprint(\"AUC-ROC  :\", roc_auc_score(y_test, pred_prob))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:31:24.841432Z","iopub.execute_input":"2025-07-23T10:31:24.842036Z","iopub.status.idle":"2025-07-23T10:31:25.456817Z","shell.execute_reply.started":"2025-07-23T10:31:24.842009Z","shell.execute_reply":"2025-07-23T10:31:25.456070Z"}},"outputs":[{"name":"stdout","text":"Accuracy : 0.6106739883383622\nF1-score : 0.5386251537762856\nAUC-ROC  : 0.6586155058661158\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"Improve Scores","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 1. SETUP & IMPORTS\n# =============================================================================\nimport os\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm.auto import tqdm\ntqdm.pandas()  # enable DataFrame.progress_apply()\n\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\n# =============================================================================\n# 2. CONFIGURATION\n# =============================================================================\nCSV_PATH        = '/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_1sec.csv'\nPRED_HORIZON    = 10                # seconds ahead to predict\nTEST_SIZE_RATIO = 0.2               # 20% hold-out\nBATCH_SIZE      = 50_000            # for batched inference\nXGB_ROUNDS      = 300               # max boosting rounds\nEARLY_STOPPING  = 30                # for validation\nGPU_ID          = 0                 # GPU index\n\n# =============================================================================\n# 3. LOAD & TARGET CREATION\n# =============================================================================\nprint(\"📥 Loading data …\")\ndf = pd.read_csv(CSV_PATH, low_memory=False)\n\nprint(\"🎯 Creating future midpoint & direction …\")\nwith tqdm(total=2, desc=\"Target shift\") as bar:\n    df['future_midpoint'] = df['midpoint'].shift(-PRED_HORIZON); bar.update(1)\n    df['price_direction'] = (df['future_midpoint'] > df['midpoint']).astype(int); bar.update(1)\ndf.dropna(subset=['price_direction'], inplace=True)\n\n# =============================================================================\n# 4. FEATURE ENGINEERING\n# =============================================================================\nprint(\"⚙️ Engineering features …\")\n\ndef compute_order_imbalance(row):\n    bid = sum(row[f'bids_notional_{i}'] for i in range(15))\n    ask = sum(row[f'asks_notional_{i}'] for i in range(15))\n    return 0 if (bid + ask)==0 else (bid - ask) / (bid + ask)\n\n# row-wise imbalance\ndf['order_imbalance'] = df.progress_apply(compute_order_imbalance, axis=1)\n\n# VWAP features\nfor side in ['bids', 'asks']:\n    prices, vols = [], []\n    for i in range(5):\n        dist_col = f'{side[:-1]}s_distance_{i}'  # 'bids_distance_i'\n        price = df['midpoint'] * (1 + (df[dist_col] / 100) * (1 if side=='asks' else -1))\n        vol   = df[f'{side}_notional_{i}']\n        prices.append(price); vols.append(vol)\n    df[f'{side}_vwap'] = sum(p*v for p,v in zip(prices, vols)) / (sum(vols)+1e-8)\ndf['vwap_mid'] = (df['bids_vwap'] + df['asks_vwap']) / 2\n\n# Spread ratio, market/limit ratios, cancel pressure\ndf['relative_spread'] = df['spread'] / df['midpoint']\ndf['bid_market_ratio'] = df[[c for c in df if 'bids_market_notional_' in c]].sum(axis=1) / \\\n                         (df[[c for c in df if 'bids_limit_notional_'  in c]].sum(axis=1)+1e-8)\ndf['ask_market_ratio'] = df[[c for c in df if 'asks_market_notional_' in c]].sum(axis=1) / \\\n                         (df[[c for c in df if 'asks_limit_notional_'  in c]].sum(axis=1)+1e-8)\ndf['cancel_pressure']  = (df[[c for c in df if 'bids_cancel_notional_' in c]].sum(axis=1) - \\\n                         df[[c for c in df if 'asks_cancel_notional_' in c]].sum(axis=1)) / \\\n                        (df[[c for c in df if 'bids_cancel_notional_' in c]].sum(axis=1) + \\\n                         df[[c for c in df if 'asks_cancel_notional_' in c]].sum(axis=1) + 1e-8)\n\n# Momentum\ndf['mid_ret_1'] = df['midpoint'].pct_change(1).fillna(0)\ndf['mid_ret_5'] = df['midpoint'].pct_change(5).fillna(0)\ndf['mid_vol30'] = df['mid_ret_1'].rolling(30).std().fillna(0)\n\n# =============================================================================\n# 5. TRAIN/TEST SPLIT\n# =============================================================================\nsplit_idx = int(len(df) * (1 - TEST_SIZE_RATIO))\ntrain_df, test_df = df.iloc[:split_idx], df.iloc[split_idx:]\nprint(f\"🚂 Train rows: {len(train_df):,} | 🧪 Test rows: {len(test_df):,}\")\n\n# =============================================================================\n# 6. MATRIX PREPARATION\n# =============================================================================\nexclude = {'index','system_time','future_midpoint','price_direction'}\nfeatures = [c for c in df.columns if c not in exclude and df[c].dtype!='object']\ndtrain = xgb.DMatrix(train_df[features], label=train_df['price_direction'])\ndtest  = xgb.DMatrix(test_df[features],  label=test_df['price_direction'])\n\n# =============================================================================\n# 7. XGBOOST GPU TRAINING\n# =============================================================================\nprint(\"🏋️ Training XGBoost on GPU …\")\nparams = {\n    'objective'      :'binary:logistic',\n    'eval_metric'    :'auc',\n    'tree_method'    :'gpu_hist',\n    'predictor'      :'gpu_predictor',\n    'gpu_id'         : GPU_ID,\n    'learning_rate'  : 0.05,\n    'max_depth'      : 6,\n    'subsample'      : 0.8,\n    'colsample_bytree':0.8,\n}\nmodel = xgb.train(\n    params,\n    dtrain,\n    num_boost_round= XGB_ROUNDS,\n    evals=[(dtrain,'train'),(dtest,'valid')],\n    early_stopping_rounds=EARLY_STOPPING,\n    verbose_eval=25\n)\n\n# =============================================================================\n# 8. BATCHED INFERENCE & METRICS\n# =============================================================================\nprint(\"🔍 Scoring test set …\")\npred_prob, pred_bin = [], []\nfor start in tqdm(range(0, len(test_df), BATCH_SIZE), desc=\"Batches\"):\n    end   = min(start + BATCH_SIZE, len(test_df))\n    batch = xgb.DMatrix(test_df[features].iloc[start:end])\n    p     = model.predict(batch)\n    pred_prob.extend(p)\n    pred_bin.extend((p > 0.5).astype(int))\n\nacc = accuracy_score(test_df['price_direction'], pred_bin)\nf1  = f1_score(      test_df['price_direction'], pred_bin)\nauc = roc_auc_score(test_df['price_direction'], pred_prob)\n\n# =============================================================================\n# 9. RESULTS\n# =============================================================================\nprint(\"\\n=== FINAL METRICS ===\")\nprint(f\"Accuracy : {acc:.4f}\")\nprint(f\"F1-score : {f1:.4f}\")\nprint(f\"AUC-ROC  : {auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T10:34:17.074339Z","iopub.execute_input":"2025-07-23T10:34:17.074786Z","iopub.status.idle":"2025-07-23T10:36:23.494691Z","shell.execute_reply.started":"2025-07-23T10:34:17.074765Z","shell.execute_reply":"2025-07-23T10:36:23.493849Z"}},"outputs":[{"name":"stdout","text":"📥 Loading data …\n🎯 Creating future midpoint & direction …\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Target shift:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e8b870a9830498cb63ceb680109b5db"}},"metadata":{}},{"name":"stdout","text":"⚙️ Engineering features …\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1030728 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ee0a790f554746867d7c8d12088725"}},"metadata":{}},{"name":"stdout","text":"🚂 Train rows: 824,582 | 🧪 Test rows: 206,146\n🏋️ Training XGBoost on GPU …\n[0]\ttrain-auc:0.69289\tvalid-auc:0.64026\n[25]\ttrain-auc:0.70994\tvalid-auc:0.65991\n[50]\ttrain-auc:0.71470\tvalid-auc:0.66218\n[75]\ttrain-auc:0.71850\tvalid-auc:0.66340\n[100]\ttrain-auc:0.72170\tvalid-auc:0.66394\n[125]\ttrain-auc:0.72460\tvalid-auc:0.66377\n[150]\ttrain-auc:0.72719\tvalid-auc:0.66378\n[154]\ttrain-auc:0.72758\tvalid-auc:0.66407\n🔍 Scoring test set …\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b526c262413453c97529d5c4b503453"}},"metadata":{}},{"name":"stdout","text":"\n=== FINAL METRICS ===\nAccuracy : 0.6124\nF1-score : 0.5851\nAUC-ROC  : 0.6641\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# =============================================================================\n# End-to-End DeepLOB-Style LOB Direction Model with tqdm\n# =============================================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\n\n# Enable tqdm for pandas\ntqdm.pandas()\n\n# --------------------\n# 1. CONFIGURATION\n# --------------------\nCSV_PATH     = '/kaggle/input/high-frequency-crypto-limit-order-book-data/BTC_1sec.csv'\nPRED_HORIZON = 10            # seconds ahead to predict\nTEST_RATIO   = 0.2           # 20% hold-out\nBATCH_SIZE   = 256           # for training/inference\nEPOCHS       = 100\nPATIENCE     = 10\nLR_FACTOR    = 0.5\n\n# --------------------\n# 2. LOAD & PREPROCESS\n# --------------------\nprint(\"📥 Loading CSV\")\ndf = pd.read_csv(CSV_PATH, low_memory=False)\n\nfrom tqdm.auto import tqdm\n\nprint(\"🎯 Creating targets\")\npbar = tqdm(total=2, desc=\"Target shift\")\ndf['future_midpoint']  = df['midpoint'].shift(-PRED_HORIZON)\npbar.update(1)\ndf['price_direction']  = (df['future_midpoint'] > df['midpoint']).astype(int)\npbar.update(1)\npbar.close()\ndf.dropna(subset=['price_direction'], inplace=True)\n\n# --------------------\n# 3. FEATURE ENGINEERING\n# --------------------\nprint(\"⚙️  Feature engineering\")\n\ndef order_imbalance(row):\n    bid = sum(row[f'bids_notional_{i}'] for i in range(15))\n    ask = sum(row[f'asks_notional_{i}'] for i in range(15))\n    return 0 if (bid+ask)==0 else (bid-ask)/(bid+ask)\n\ndf['imbalance'] = df.progress_apply(order_imbalance, axis=1)\n\n# Build tensor input: sliding windows of length PRED_HORIZON+1\nLEVELS   = 10  # top N levels\nFEATURES = 4   # distance, notional, imbalance, spread\nWINDOW   = PRED_HORIZON + 1\n\n# pre-allocate\nX, y = [], []\ncols_dist   = [f'bids_distance_{i}' for i in range(LEVELS)] + [f'asks_distance_{i}' for i in range(LEVELS)]\ncols_notional = [f'bids_notional_{i}' for i in range(LEVELS)] + [f'asks_notional_{i}' for i in range(LEVELS)]\n\nprint(\"🔄 Building time-series windows\")\nfor i in tqdm(range(len(df) - WINDOW)):\n    window = df.iloc[i:i+WINDOW]\n    # tensor shape: (WINDOW, LEVELS*2 features)\n    dist    = window[cols_dist].values\n    notional= window[cols_notional].values\n    imb     = window['imbalance'].values.reshape(-1,1)\n    spr     = window['spread'].values.reshape(-1,1)\n    # stack features: [dist, notional, imb, spr]\n    frame = np.concatenate([dist, notional, imb, spr], axis=1)\n    X.append(frame)\n    y.append(window['price_direction'].iloc[-1])\n\nX = np.array(X, dtype=np.float32)  # shape=(samples, WINDOW, FEATURES_TOTAL)\ny = np.array(y, dtype=np.int8)\n\n# --------------------\n# 4. TRAIN/VAL SPLIT\n# --------------------\nsplit = int(len(X) * (1 - TEST_RATIO))\nX_train, X_val = X[:split], X[split:]\ny_train, y_val = y[:split], y[split:]\nprint(f\"🚂 Train: {len(X_train)} samples | 🧪 Val: {len(X_val)} samples\")\n\n# --------------------\n# 5. MODEL DEFINITION\n# --------------------\ndef build_deeplob(input_shape):\n    inp = layers.Input(shape=input_shape)\n    # Convolutional block\n    x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(inp)\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv1D(32, kernel_size=5, activation='relu', padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    # LSTM block\n    x = layers.LSTM(128, return_sequences=True, dropout=0.2)(x)\n    x = layers.LSTM(64, dropout=0.2)(x)\n    # Dense head\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    out = layers.Dense(1, activation='sigmoid')(x)\n    return models.Model(inp, out)\n\nfeat_dim = (LEVELS*2) + (LEVELS*2) + 2  # 42\nmodel = build_deeplob(input_shape=(WINDOW, feat_dim))\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=[tf.keras.metrics.AUC(name='auc')])\n\nmodel.summary()\n\n# --------------------\n# 6. TRAINING\n# --------------------\nes = callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=PATIENCE, restore_best_weights=True)\nrlr= callbacks.ReduceLROnPlateau(monitor='val_loss', factor=LR_FACTOR, patience=5, verbose=1)\n\nprint(\"🏋️ Training DeepLOB model\")\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    callbacks=[es, rlr],\n    verbose=1\n)\n\n# --------------------\n# 7. EVALUATION\n# --------------------\nprint(\"🔍 Evaluating on validation set\")\ny_pred_prob = model.predict(X_val, batch_size=BATCH_SIZE, verbose=1).flatten()\ny_pred_bin  = (y_pred_prob > 0.5).astype(int)\n\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nacc = accuracy_score(y_val, y_pred_bin)\nf1  = f1_score(y_val, y_pred_bin)\nauc = roc_auc_score(y_val, y_pred_prob)\n\nprint(f\"\\n=== FINAL VALIDATION METRICS ===\")\nprint(f\"Accuracy : {acc:.4f}\")\nprint(f\"F1-Score : {f1:.4f}\")\nprint(f\"AUC-ROC  : {auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:14:27.058389Z","iopub.execute_input":"2025-07-23T11:14:27.058684Z"}},"outputs":[{"name":"stdout","text":"📥 Loading CSV\n🎯 Creating targets\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Target shift:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e98b6001541418bab62518628414883"}},"metadata":{}},{"name":"stdout","text":"⚙️  Feature engineering\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1030728 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e3c618952424cf8a6801bc3b093f75f"}},"metadata":{}},{"name":"stdout","text":"🔄 Building time-series windows\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1030717 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64613577952646769320e37729dd8414"}},"metadata":{}},{"name":"stdout","text":"🚂 Train: 824573 samples | 🧪 Val: 206144 samples\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m42\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,128\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m10,272\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m82,432\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,128</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m154,849\u001b[0m (604.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,849</span> (604.88 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m154,657\u001b[0m (604.13 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,657</span> (604.13 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"🏋️ Training DeepLOB model\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1753270354.808329     175 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 11ms/step - auc: 0.6691 - loss: 0.6325 - val_auc: 0.6406 - val_loss: 0.6544 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - auc: 0.6895 - loss: 0.6211 - val_auc: 0.6380 - val_loss: 0.6562 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 10ms/step - auc: 0.6957 - loss: 0.6169 - val_auc: 0.6381 - val_loss: 0.6561 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - auc: 0.7017 - loss: 0.6131 - val_auc: 0.6309 - val_loss: 0.6603 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m3217/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - auc: 0.7082 - loss: 0.6085","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}